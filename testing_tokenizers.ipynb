{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitbasepytorchhuggingfaceconda3d719d8b2d364699aeaa0f91124859a2",
   "display_name": "Python 3.8.1 64-bit ('base[pytorch-huggingface]': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using cache found in C:\\Users\\uunal/.cache\\torch\\hub\\huggingface_pytorch-transformers_master\n"
    }
   ],
   "source": [
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')\n",
    "\n",
    "text_1 = \"session opened for user root by zero\"\n",
    "text_2 = \"session closed for user root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenized input with special tokens around it (for BERT: [CLS] at the beginning and [SEP] at the end)\n",
    "indexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[101,\n 4912,\n 1533,\n 1111,\n 4795,\n 7261,\n 1118,\n 6756,\n 102,\n 4912,\n 1804,\n 1111,\n 4795,\n 7261,\n 102]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using cache found in C:\\Users\\uunal/.cache\\torch\\hub\\huggingface_pytorch-transformers_master\n"
    }
   ],
   "source": [
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-cased')\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using cache found in C:\\Users\\uunal/.cache\\torch\\hub\\huggingface_pytorch-transformers_master\n"
    }
   ],
   "source": [
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = 7\n",
    "indexed_tokens[masked_index] = tokenizer.mask_token_id\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "masked_lm__model = torch.hub.load('huggingface/pytorch-transformers', 'modelWithLMHead', 'bert-base-cased')\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = masked_lm__model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "\n",
    "# Get the predicted token\n",
    "predicted_index = torch.argmax(predictions[0][0], dim=1)[masked_index].item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "# assert predicted_token == 'Jim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'zero'"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([torch.argmax(predictions[0][0], dim=1)[7].item()])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4912"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(predictions[0][0], dim=1)[9].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 119, 4912, 1533, 1111, 4795, 7261, 1118, 6756,  132, 4912, 1804, 1111,\n        4795, 7261,  119])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(predictions[0][0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'default'"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}